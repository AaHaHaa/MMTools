//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-33191640
// Cuda compilation tools, release 12.2, V12.2.140
// Based on NVVM 7.0.1
//

.version 8.2
.target sm_50
.address_size 64

	// .globl	_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj
// _ZZ21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjjE7this_At has been demoted

.visible .entry _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj(
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_0,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_1,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_2,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_3,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_4,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_5,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_6,
	.param .u64 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_7,
	.param .u8 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_8,
	.param .u32 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_9,
	.param .u32 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_10,
	.param .u32 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_11,
	.param .u32 _Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_12
)
{
	.reg .pred 	%p<28>;
	.reg .b16 	%rs<22>;
	.reg .b32 	%r<144>;
	.reg .f64 	%fd<222>;
	.reg .b64 	%rd<76>;
	// demoted variable
	.shared .align 16 .b8 _ZZ21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjjE7this_At[512];

	ld.param.s8 	%rs1, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_8];
	ld.param.u64 	%rd30, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_0];
	ld.param.u64 	%rd31, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_1];
	ld.param.u64 	%rd32, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_2];
	ld.param.u64 	%rd35, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_3];
	ld.param.u64 	%rd36, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_4];
	ld.param.u64 	%rd37, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_5];
	ld.param.u64 	%rd33, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_6];
	ld.param.u64 	%rd34, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_7];
	ld.param.u32 	%r31, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_9];
	ld.param.u32 	%r32, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_10];
	ld.param.u32 	%r33, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_11];
	ld.param.u32 	%r30, [_Z21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjj_param_12];
	cvta.to.global.u64 	%rd1, %rd35;
	cvta.to.global.u64 	%rd2, %rd36;
	cvta.to.global.u64 	%rd3, %rd37;
	mov.u32 	%r1, %tid.x;
	div.u32 	%r2, %r1, %r33;
	mul.lo.s32 	%r34, %r2, %r33;
	sub.s32 	%r3, %r1, %r34;
	mov.u32 	%r4, %ctaid.x;
	div.u32 	%r5, %r4, %r30;
	mul.lo.s32 	%r6, %r32, %r31;
	mul.lo.s32 	%r7, %r6, %r33;
	setp.ge.u32 	%p1, %r1, %r33;
	shl.b32 	%r35, %r3, 4;
	mov.u32 	%r36, _ZZ21GMMNLSE_nonlinear_sumP7double2S0_PKS_PKdS4_PKhPKjS8_bjjjjE7this_At;
	add.s32 	%r8, %r36, %r35;
	@%p1 bra 	$L__BB0_2;

	cvta.to.global.u64 	%rd38, %rd32;
	mad.lo.s32 	%r37, %r3, %r6, %r5;
	mul.wide.u32 	%rd39, %r37, 16;
	add.s64 	%rd40, %rd38, %rd39;
	ld.global.v4.u32 	{%r38, %r39, %r40, %r41}, [%rd40];
	st.shared.v4.u32 	[%r8], {%r38, %r39, %r40, %r41};

$L__BB0_2:
	bar.sync 	0;
	cvta.to.global.u64 	%rd41, %rd33;
	mul.wide.u32 	%rd42, %r1, 4;
	add.s64 	%rd43, %rd41, %rd42;
	ld.global.s32 	%rd5, [%rd43];
	cvta.to.global.u64 	%rd44, %rd34;
	add.s64 	%rd45, %rd44, %rd42;
	ld.global.u32 	%r9, [%rd45];
	mul.lo.s32 	%r47, %r5, %r30;
	sub.s32 	%r46, %r4, %r47;
	setp.eq.s32 	%p2, %r46, 0;
	@%p2 bra 	$L__BB0_13;

	setp.ne.s32 	%p3, %r46, 1;
	@%p3 bra 	$L__BB0_22;

	cvt.u32.u64 	%r48, %rd5;
	setp.eq.s32 	%p4, %r48, 0;
	setp.eq.s16 	%p5, %rs1, 0;
	or.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB0_22;

	add.s32 	%r138, %r48, -1;
	add.s32 	%r11, %r9, -1;
	setp.ge.u32 	%p7, %r138, %r11;
	mov.f64 	%fd24, 0d0000000000000000;
	mov.f64 	%fd211, %fd24;
	@%p7 bra 	$L__BB0_12;

	sub.s32 	%r51, %r9, %r48;
	and.b32  	%r137, %r51, 3;
	setp.eq.s32 	%p8, %r137, 0;
	mov.f64 	%fd211, 0d0000000000000000;
	@%p8 bra 	$L__BB0_9;

	shl.b64 	%rd46, %rd5, 3;
	add.s64 	%rd47, %rd2, %rd46;
	add.s64 	%rd69, %rd47, -8;
	shl.b32 	%r53, %r48, 2;
	cvt.s64.s32 	%rd48, %r53;
	add.s64 	%rd49, %rd3, %rd48;
	add.s64 	%rd68, %rd49, -1;

$L__BB0_8:
	.pragma "nounroll";
	ld.global.u8 	%rs2, [%rd68+-1];
	cvt.u32.u16 	%r54, %rs2;
	ld.global.u8 	%rs3, [%rd68];
	cvt.u32.u16 	%r55, %rs3;
	mul.wide.u16 	%r56, %rs2, 16;
	add.s32 	%r58, %r36, %r56;
	ld.shared.v2.f64 	{%fd28, %fd29}, [%r58+-16];
	mul.wide.u16 	%r59, %rs3, 16;
	add.s32 	%r60, %r36, %r59;
	ld.shared.v2.f64 	{%fd32, %fd33}, [%r60+-16];
	setp.eq.s32 	%p9, %r54, %r55;
	mul.f64 	%fd36, %fd29, %fd33;
	fma.rn.f64 	%fd37, %fd28, %fd32, %fd36;
	ld.global.f64 	%fd38, [%rd69];
	mul.f64 	%fd39, %fd38, %fd37;
	add.f64 	%fd40, %fd39, %fd39;
	selp.f64 	%fd41, %fd39, %fd40, %p9;
	add.f64 	%fd211, %fd211, %fd41;
	add.s32 	%r138, %r138, 1;
	add.s64 	%rd69, %rd69, 8;
	add.s64 	%rd68, %rd68, 4;
	add.s32 	%r137, %r137, -1;
	setp.ne.s32 	%p10, %r137, 0;
	@%p10 bra 	$L__BB0_8;

$L__BB0_9:
	not.b32 	%r62, %r48;
	add.s32 	%r63, %r9, %r62;
	setp.lt.u32 	%p11, %r63, 3;
	@%p11 bra 	$L__BB0_12;

	mul.wide.s32 	%rd50, %r138, 8;
	add.s64 	%rd51, %rd2, %rd50;
	add.s64 	%rd71, %rd51, 16;
	shl.b32 	%r64, %r138, 2;
	cvt.s64.s32 	%rd52, %r64;
	add.s64 	%rd53, %rd3, %rd52;
	add.s64 	%rd70, %rd53, 7;

$L__BB0_11:
	ld.global.u8 	%rs4, [%rd70+-5];
	cvt.u32.u16 	%r65, %rs4;
	ld.global.u8 	%rs5, [%rd70+-4];
	cvt.u32.u16 	%r66, %rs5;
	mul.wide.u16 	%r67, %rs4, 16;
	add.s32 	%r69, %r36, %r67;
	ld.shared.v2.f64 	{%fd42, %fd43}, [%r69+-16];
	mul.wide.u16 	%r70, %rs5, 16;
	add.s32 	%r71, %r36, %r70;
	ld.shared.v2.f64 	{%fd46, %fd47}, [%r71+-16];
	setp.eq.s32 	%p12, %r65, %r66;
	mul.f64 	%fd50, %fd43, %fd47;
	fma.rn.f64 	%fd51, %fd42, %fd46, %fd50;
	ld.global.f64 	%fd52, [%rd71+-16];
	mul.f64 	%fd53, %fd52, %fd51;
	add.f64 	%fd54, %fd53, %fd53;
	selp.f64 	%fd55, %fd53, %fd54, %p12;
	add.f64 	%fd56, %fd211, %fd55;
	ld.global.u8 	%rs6, [%rd70+-1];
	cvt.u32.u16 	%r72, %rs6;
	ld.global.u8 	%rs7, [%rd70];
	cvt.u32.u16 	%r73, %rs7;
	mul.wide.u16 	%r74, %rs6, 16;
	add.s32 	%r75, %r36, %r74;
	ld.shared.v2.f64 	{%fd57, %fd58}, [%r75+-16];
	mul.wide.u16 	%r76, %rs7, 16;
	add.s32 	%r77, %r36, %r76;
	ld.shared.v2.f64 	{%fd61, %fd62}, [%r77+-16];
	setp.eq.s32 	%p13, %r72, %r73;
	mul.f64 	%fd65, %fd58, %fd62;
	fma.rn.f64 	%fd66, %fd57, %fd61, %fd65;
	ld.global.f64 	%fd67, [%rd71+-8];
	mul.f64 	%fd68, %fd67, %fd66;
	add.f64 	%fd69, %fd68, %fd68;
	selp.f64 	%fd70, %fd68, %fd69, %p13;
	add.f64 	%fd71, %fd56, %fd70;
	ld.global.u8 	%rs8, [%rd70+3];
	cvt.u32.u16 	%r78, %rs8;
	ld.global.u8 	%rs9, [%rd70+4];
	cvt.u32.u16 	%r79, %rs9;
	mul.wide.u16 	%r80, %rs8, 16;
	add.s32 	%r81, %r36, %r80;
	ld.shared.v2.f64 	{%fd72, %fd73}, [%r81+-16];
	mul.wide.u16 	%r82, %rs9, 16;
	add.s32 	%r83, %r36, %r82;
	ld.shared.v2.f64 	{%fd76, %fd77}, [%r83+-16];
	setp.eq.s32 	%p14, %r78, %r79;
	mul.f64 	%fd80, %fd73, %fd77;
	fma.rn.f64 	%fd81, %fd72, %fd76, %fd80;
	ld.global.f64 	%fd82, [%rd71];
	mul.f64 	%fd83, %fd82, %fd81;
	add.f64 	%fd84, %fd83, %fd83;
	selp.f64 	%fd85, %fd83, %fd84, %p14;
	add.f64 	%fd86, %fd71, %fd85;
	ld.global.u8 	%rs10, [%rd70+7];
	cvt.u32.u16 	%r84, %rs10;
	ld.global.u8 	%rs11, [%rd70+8];
	cvt.u32.u16 	%r85, %rs11;
	mul.wide.u16 	%r86, %rs10, 16;
	add.s32 	%r87, %r36, %r86;
	ld.shared.v2.f64 	{%fd87, %fd88}, [%r87+-16];
	mul.wide.u16 	%r88, %rs11, 16;
	add.s32 	%r89, %r36, %r88;
	ld.shared.v2.f64 	{%fd91, %fd92}, [%r89+-16];
	setp.eq.s32 	%p15, %r84, %r85;
	mul.f64 	%fd95, %fd88, %fd92;
	fma.rn.f64 	%fd96, %fd87, %fd91, %fd95;
	ld.global.f64 	%fd97, [%rd71+8];
	mul.f64 	%fd98, %fd97, %fd96;
	add.f64 	%fd99, %fd98, %fd98;
	selp.f64 	%fd100, %fd98, %fd99, %p15;
	add.f64 	%fd211, %fd86, %fd100;
	add.s64 	%rd71, %rd71, 32;
	add.s64 	%rd70, %rd70, 16;
	add.s32 	%r138, %r138, 4;
	setp.lt.u32 	%p16, %r138, %r11;
	@%p16 bra 	$L__BB0_11;

$L__BB0_12:
	mad.lo.s32 	%r90, %r2, %r6, %r5;
	mad.lo.s32 	%r91, %r3, %r7, %r90;
	cvta.to.global.u64 	%rd54, %rd31;
	mul.wide.u32 	%rd55, %r91, 16;
	add.s64 	%rd56, %rd54, %rd55;
	st.global.v2.f64 	[%rd56], {%fd211, %fd24};
	bra.uni 	$L__BB0_22;

$L__BB0_13:
	cvt.u32.u64 	%r92, %rd5;
	setp.eq.s32 	%p17, %r92, 0;
	@%p17 bra 	$L__BB0_22;

	ld.shared.v2.f64 	{%fd104, %fd105}, [%r8];
	add.s32 	%r142, %r92, -1;
	add.s32 	%r21, %r9, -1;
	setp.ge.u32 	%p18, %r142, %r21;
	mov.f64 	%fd220, 0d0000000000000000;
	mov.f64 	%fd221, %fd220;
	@%p18 bra 	$L__BB0_21;

	sub.s32 	%r95, %r9, %r92;
	and.b32  	%r141, %r95, 3;
	setp.eq.s32 	%p19, %r141, 0;
	mov.f64 	%fd221, 0d0000000000000000;
	mov.f64 	%fd220, %fd221;
	@%p19 bra 	$L__BB0_18;

	shl.b64 	%rd57, %rd5, 3;
	add.s64 	%rd58, %rd1, %rd57;
	add.s64 	%rd73, %rd58, -8;
	shl.b32 	%r97, %r92, 2;
	cvt.s64.s32 	%rd59, %r97;
	add.s64 	%rd60, %rd3, %rd59;
	add.s64 	%rd72, %rd60, -1;

$L__BB0_17:
	.pragma "nounroll";
	ld.global.u8 	%rs12, [%rd72+-1];
	cvt.u32.u16 	%r98, %rs12;
	ld.global.u8 	%rs13, [%rd72];
	cvt.u32.u16 	%r99, %rs13;
	mul.wide.u16 	%r100, %rs12, 16;
	add.s32 	%r102, %r36, %r100;
	ld.shared.v2.f64 	{%fd111, %fd112}, [%r102+-16];
	mul.wide.u16 	%r103, %rs13, 16;
	add.s32 	%r104, %r36, %r103;
	ld.shared.v2.f64 	{%fd115, %fd116}, [%r104+-16];
	mul.f64 	%fd119, %fd112, %fd116;
	fma.rn.f64 	%fd120, %fd111, %fd115, %fd119;
	ld.global.f64 	%fd121, [%rd73];
	mul.f64 	%fd122, %fd121, %fd120;
	setp.eq.s32 	%p20, %r98, %r99;
	mul.f64 	%fd123, %fd104, %fd122;
	mul.f64 	%fd124, %fd105, %fd122;
	add.f64 	%fd125, %fd123, %fd123;
	add.f64 	%fd126, %fd124, %fd124;
	selp.f64 	%fd127, %fd123, %fd125, %p20;
	selp.f64 	%fd128, %fd124, %fd126, %p20;
	add.f64 	%fd221, %fd221, %fd128;
	add.f64 	%fd220, %fd220, %fd127;
	add.s32 	%r142, %r142, 1;
	add.s64 	%rd73, %rd73, 8;
	add.s64 	%rd72, %rd72, 4;
	add.s32 	%r141, %r141, -1;
	setp.ne.s32 	%p21, %r141, 0;
	@%p21 bra 	$L__BB0_17;

$L__BB0_18:
	not.b32 	%r106, %r92;
	add.s32 	%r107, %r9, %r106;
	setp.lt.u32 	%p22, %r107, 3;
	@%p22 bra 	$L__BB0_21;

	mul.wide.s32 	%rd61, %r142, 8;
	add.s64 	%rd62, %rd1, %rd61;
	add.s64 	%rd75, %rd62, 16;
	shl.b32 	%r108, %r142, 2;
	cvt.s64.s32 	%rd63, %r108;
	add.s64 	%rd64, %rd3, %rd63;
	add.s64 	%rd74, %rd64, 7;

$L__BB0_20:
	ld.global.u8 	%rs14, [%rd74+-5];
	cvt.u32.u16 	%r109, %rs14;
	ld.global.u8 	%rs15, [%rd74+-4];
	cvt.u32.u16 	%r110, %rs15;
	mul.wide.u16 	%r111, %rs14, 16;
	add.s32 	%r113, %r36, %r111;
	ld.shared.v2.f64 	{%fd129, %fd130}, [%r113+-16];
	mul.wide.u16 	%r114, %rs15, 16;
	add.s32 	%r115, %r36, %r114;
	ld.shared.v2.f64 	{%fd133, %fd134}, [%r115+-16];
	mul.f64 	%fd137, %fd130, %fd134;
	fma.rn.f64 	%fd138, %fd129, %fd133, %fd137;
	ld.global.f64 	%fd139, [%rd75+-16];
	mul.f64 	%fd140, %fd139, %fd138;
	setp.eq.s32 	%p23, %r109, %r110;
	mul.f64 	%fd141, %fd104, %fd140;
	mul.f64 	%fd142, %fd105, %fd140;
	add.f64 	%fd143, %fd141, %fd141;
	add.f64 	%fd144, %fd142, %fd142;
	selp.f64 	%fd145, %fd141, %fd143, %p23;
	selp.f64 	%fd146, %fd142, %fd144, %p23;
	add.f64 	%fd147, %fd221, %fd146;
	add.f64 	%fd148, %fd220, %fd145;
	ld.global.u8 	%rs16, [%rd74+-1];
	cvt.u32.u16 	%r116, %rs16;
	ld.global.u8 	%rs17, [%rd74];
	cvt.u32.u16 	%r117, %rs17;
	mul.wide.u16 	%r118, %rs16, 16;
	add.s32 	%r119, %r36, %r118;
	ld.shared.v2.f64 	{%fd149, %fd150}, [%r119+-16];
	mul.wide.u16 	%r120, %rs17, 16;
	add.s32 	%r121, %r36, %r120;
	ld.shared.v2.f64 	{%fd153, %fd154}, [%r121+-16];
	mul.f64 	%fd157, %fd150, %fd154;
	fma.rn.f64 	%fd158, %fd149, %fd153, %fd157;
	ld.global.f64 	%fd159, [%rd75+-8];
	mul.f64 	%fd160, %fd159, %fd158;
	setp.eq.s32 	%p24, %r116, %r117;
	mul.f64 	%fd161, %fd104, %fd160;
	mul.f64 	%fd162, %fd105, %fd160;
	add.f64 	%fd163, %fd161, %fd161;
	add.f64 	%fd164, %fd162, %fd162;
	selp.f64 	%fd165, %fd161, %fd163, %p24;
	selp.f64 	%fd166, %fd162, %fd164, %p24;
	add.f64 	%fd167, %fd147, %fd166;
	add.f64 	%fd168, %fd148, %fd165;
	ld.global.u8 	%rs18, [%rd74+3];
	cvt.u32.u16 	%r122, %rs18;
	ld.global.u8 	%rs19, [%rd74+4];
	cvt.u32.u16 	%r123, %rs19;
	mul.wide.u16 	%r124, %rs18, 16;
	add.s32 	%r125, %r36, %r124;
	ld.shared.v2.f64 	{%fd169, %fd170}, [%r125+-16];
	mul.wide.u16 	%r126, %rs19, 16;
	add.s32 	%r127, %r36, %r126;
	ld.shared.v2.f64 	{%fd173, %fd174}, [%r127+-16];
	mul.f64 	%fd177, %fd170, %fd174;
	fma.rn.f64 	%fd178, %fd169, %fd173, %fd177;
	ld.global.f64 	%fd179, [%rd75];
	mul.f64 	%fd180, %fd179, %fd178;
	setp.eq.s32 	%p25, %r122, %r123;
	mul.f64 	%fd181, %fd104, %fd180;
	mul.f64 	%fd182, %fd105, %fd180;
	add.f64 	%fd183, %fd181, %fd181;
	add.f64 	%fd184, %fd182, %fd182;
	selp.f64 	%fd185, %fd181, %fd183, %p25;
	selp.f64 	%fd186, %fd182, %fd184, %p25;
	add.f64 	%fd187, %fd167, %fd186;
	add.f64 	%fd188, %fd168, %fd185;
	ld.global.u8 	%rs20, [%rd74+7];
	cvt.u32.u16 	%r128, %rs20;
	ld.global.u8 	%rs21, [%rd74+8];
	cvt.u32.u16 	%r129, %rs21;
	mul.wide.u16 	%r130, %rs20, 16;
	add.s32 	%r131, %r36, %r130;
	ld.shared.v2.f64 	{%fd189, %fd190}, [%r131+-16];
	mul.wide.u16 	%r132, %rs21, 16;
	add.s32 	%r133, %r36, %r132;
	ld.shared.v2.f64 	{%fd193, %fd194}, [%r133+-16];
	mul.f64 	%fd197, %fd190, %fd194;
	fma.rn.f64 	%fd198, %fd189, %fd193, %fd197;
	ld.global.f64 	%fd199, [%rd75+8];
	mul.f64 	%fd200, %fd199, %fd198;
	setp.eq.s32 	%p26, %r128, %r129;
	mul.f64 	%fd201, %fd104, %fd200;
	mul.f64 	%fd202, %fd105, %fd200;
	add.f64 	%fd203, %fd201, %fd201;
	add.f64 	%fd204, %fd202, %fd202;
	selp.f64 	%fd205, %fd201, %fd203, %p26;
	selp.f64 	%fd206, %fd202, %fd204, %p26;
	add.f64 	%fd221, %fd187, %fd206;
	add.f64 	%fd220, %fd188, %fd205;
	add.s64 	%rd75, %rd75, 32;
	add.s64 	%rd74, %rd74, 16;
	add.s32 	%r142, %r142, 4;
	setp.lt.u32 	%p27, %r142, %r21;
	@%p27 bra 	$L__BB0_20;

$L__BB0_21:
	mad.lo.s32 	%r134, %r2, %r6, %r5;
	mad.lo.s32 	%r135, %r3, %r7, %r134;
	cvta.to.global.u64 	%rd65, %rd30;
	mul.wide.u32 	%rd66, %r135, 16;
	add.s64 	%rd67, %rd65, %rd66;
	st.global.v2.f64 	[%rd67], {%fd220, %fd221};

$L__BB0_22:
	ret;

}

